# Context Data for Speech-to-Text Repository

> This voice note provides context data to an AI agent regarding a speech-to-text repository. The user outlines their plan to use multimodal audio to improve speech transcription.

*Transcribed: 8 Dec 2025 14:21*

---

Okay, so the purpose of this voice recording is primarily to provide context data to the AI agent, and of course, if anyone happens to listen to this, another human, that would be cool.

Hello human. Hello agent. I'm going to provide context data for what I'm trying to achieve in this repository and explain the idea and provide a sort of roadmap for the plan here.

So, I've created a number of speech-to-text prototypes over the past year.

Something I feel about speech transcription, having used it a lot, is that multimodal audio is, I think, where that's the way forward.

Instead of providing an audio file to a speech-to-text model, and then providing that transcription to a model, a large language model, for cleanup, as it were, it's much easier to just upload something to a multimodal model that has audio understanding as a ca-
