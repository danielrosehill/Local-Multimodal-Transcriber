Okay, so the purpose of this voice recording is primarily to provide context data to the AI agent. And of course, if anyone happens to listen to this, another human, that would be, it's cool. Hello, human. Hello, agent. I'm going to provide context data for what I'm trying to achieve in this repository and explain the idea and provide a sort of roadmap for the plan here. So I've created a number of speech-to-text prototypes over the past year. And... Something I feel about speech transcription, having used it a lot, is that multimodal audio is, I think, where that's the way forward. Instead of providing an audio file to a speech-to-text model and then providing that transcription to a model, a large language model for cleanup, as it were, I've much easier to just upload something to a multimodal model that has audio understanding as a key. I'm sorry?